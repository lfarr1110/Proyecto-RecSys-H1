{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690b87c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leopo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import implicit\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d46b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions shape: (16875399, 3)\n",
      "Items shape: (169578, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     user_id  product_id  rating\n",
       " 0  558856683     1004775       0\n",
       " 1  532364121    12708937       0\n",
       " 2  512651494    24900193       0\n",
       " 3  520037415     5100503       0\n",
       " 4  566280860    26019863       0,\n",
       "    product_id          category_id           category_code     brand   price\n",
       " 0     1004775  2053013555631882655  electronics.smartphone    xiaomi  183.27\n",
       " 1    12708937  2053013553559896355                     NaN  michelin   72.72\n",
       " 2    24900193  2053013562183385881                     NaN       NaN    1.09\n",
       " 3     5100503  2053013553375346967                     NaN    xiaomi   22.68\n",
       " 4    26019863  2053013562837697343                     NaN       NaN   11.79)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2019-Nov-half.csv')\n",
    "df.head()\n",
    "\n",
    "\n",
    "interactions = df[['user_id', 'product_id', 'event_type']].copy()\n",
    "interactions['rating'] = interactions['event_type'].apply(lambda x: 1 if x in ['cart', 'purchase'] else 0)\n",
    "\n",
    "interactions = interactions[['user_id', 'product_id', 'rating']]\n",
    "\n",
    "items = df[['product_id', 'category_id', 'category_code', 'brand', 'price']].drop_duplicates(subset=['product_id']).reset_index(drop=True)\n",
    "\n",
    "# Quick checks\n",
    "print('Interactions shape:', interactions.shape)\n",
    "print('Items shape:', items.shape)\n",
    "\n",
    "interactions.head(), items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing id maps and creating train/test splits...\n",
      "Train interactions: 15129495 Test interactions: 1745904\n",
      "Saved train/test splits and mappings to processed_data/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('processed_data', exist_ok=True)\n",
    "\n",
    "print('Preparing id maps and creating train/test splits...')\n",
    "user_ids = interactions['user_id'].unique()\n",
    "item_ids = interactions['product_id'].unique()\n",
    "\n",
    "user2idx = {u: i for i, u in enumerate(user_ids)}\n",
    "item2idx = {p: i for i, p in enumerate(item_ids)}\n",
    "\n",
    "interactions['user_idx'] = interactions['user_id'].map(user2idx)\n",
    "interactions['item_idx'] = interactions['product_id'].map(item2idx)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def leave_one_out(df, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    train_rows = []\n",
    "    test_rows = []\n",
    "    grouped = df.groupby('user_idx')\n",
    "    for user, group in grouped:\n",
    "        if len(group) == 1:\n",
    "            train_rows.append(group.index.values[0])\n",
    "        else:\n",
    "            test_idx = np.random.choice(group.index.values)\n",
    "            test_rows.append(test_idx)\n",
    "            train_rows.extend([i for i in group.index.values if i != test_idx])\n",
    "    return df.loc[train_rows].copy(), df.loc[test_rows].copy()\n",
    "\n",
    "train_df, test_df = leave_one_out(interactions, seed=42)\n",
    "print('Train interactions:', len(train_df), 'Test interactions:', len(test_df))\n",
    "\n",
    "train_df.to_csv('processed_data/train_interactions.csv', index=False)\n",
    "test_df.to_csv('processed_data/test_interactions.csv', index=False)\n",
    "pd.DataFrame(list(user2idx.items()), columns=['user_id', 'user_idx']).to_csv('processed_data/user_mapping.csv', index=False)\n",
    "pd.DataFrame(list(item2idx.items()), columns=['product_id', 'item_idx']).to_csv('processed_data/item_mapping.csv', index=False)\n",
    "\n",
    "print('Saved train/test splits and mappings to processed_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a328b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading splits and mappings...\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "\n",
    "print('Loading splits and mappings...')\n",
    "df_train = pd.read_csv('processed_data/train_interactions.csv')\n",
    "df_test = pd.read_csv('processed_data/test_interactions.csv')\n",
    "user_map = pd.read_csv('processed_data/user_mapping.csv')\n",
    "item_map = pd.read_csv('processed_data/item_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb0ee071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['user_idx', 'item_idx'], axis=1)\n",
    "df_test = df_test.drop(columns=['user_idx', 'item_idx'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = item_map.merge(items, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81149310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(r, k):\n",
    "    assert 1 <= k <= r.size\n",
    "    return (np.asarray(r)[:k]).mean()\n",
    "\n",
    "def average_precision_at_k(r, k):\n",
    "    r = np.asarray(r)\n",
    "    n_rel = r.sum()\n",
    "    if n_rel == 0:\n",
    "        return 0.\n",
    "    vectorized_precision = np.vectorize(lambda i: precision_at_k(r, i))\n",
    "    indices = np.arange(1, len(r) + 1)\n",
    "    precisions = vectorized_precision(indices)\n",
    "    score = np.sum(precisions * r)\n",
    "    return score / min(k, n_rel)\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(np.subtract(np.power(2, r), 1) / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    idcg = dcg_at_k(sorted(r, reverse=True), k)\n",
    "\n",
    "    if not idcg:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "user_items = {}\n",
    "itemset = set()\n",
    "\n",
    "for row in df_train.itertuples():\n",
    "    user_items.setdefault(row[1], []).append(row[2])\n",
    "    itemset.add(row[2])\n",
    "\n",
    "itemset = np.sort(list(itemset))\n",
    "item2idx = {item: i for i, item in enumerate(itemset)}\n",
    "user_ids = {user: i for i, user in enumerate(user_items.keys())}\n",
    "\n",
    "rows, cols, data = [], [], []\n",
    "\n",
    "for user, items in user_items.items():\n",
    "    u_idx = user_ids[user]\n",
    "    for item in items:\n",
    "        i_idx = item2idx[item]\n",
    "        rows.append(u_idx)\n",
    "        cols.append(i_idx)\n",
    "        data.append(1)\n",
    "\n",
    "sparse_matrix = csr_matrix((data, (rows, cols)), \n",
    "                           shape=(len(user_items), len(itemset)), \n",
    "                           dtype=np.int8)\n",
    "\n",
    "user_item_matrix = sparse_matrix  \n",
    "item_user_matrix = sparse_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd2b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de user id a fila de la matriz sparse\n",
    "user2row = {user_id: matrix_row for matrix_row, user_id in enumerate(user_items.keys())}\n",
    "row2user = {matrix_row: user_id for user_id, matrix_row in user2row.items()}\n",
    "\n",
    "# Mapeo de item id a columna de la matriz sparse\n",
    "item2col = {item_id: matrix_col for matrix_col, item_id in enumerate(itemset)}\n",
    "col2item = {matrix_col: item_id for item_id, matrix_col in item2col.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ed69468",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_test = {}\n",
    "\n",
    "for row in df_test.itertuples():\n",
    "    if row[1] not in user_items_test:\n",
    "        user_items_test[row[1]] = []\n",
    "\n",
    "    user_items_test[row[1]].append(row[2])\n",
    "\n",
    "def evaluate_model(model, n):\n",
    "  mean_ap = 0. # o MAP\n",
    "  mean_ndcg = 0.\n",
    "  for user_id in user_items_test.keys():\n",
    "    user_row = user2row[user_id]\n",
    "    rec = model.recommend(user_row, user_item_matrix[user_row], n)[0]\n",
    "    rec = [col2item[col] for col in rec]\n",
    "    rel_vector = np.isin(rec, user_items_test[user_id], assume_unique=True).astype(int)\n",
    "    mean_ap += average_precision_at_k(rel_vector, n)\n",
    "    mean_ndcg += ndcg_at_k(rel_vector, n)\n",
    "\n",
    "  mean_ap /= len(user_items_test)\n",
    "  mean_ndcg /= len(user_items_test)\n",
    "\n",
    "  return mean_ap, mean_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22e129b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_recommendations(model, user, n):\n",
    "  recommendations = model.recommend(userid=user, user_items=user_item_matrix[user], N=n)[0]\n",
    "  return items.loc[recommendations]['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15629413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similar_movies(model, item, n=10):\n",
    "  sim_items = model.similar_items(item, n)[0]\n",
    "  return items.loc[sim_items]['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920aacd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leopo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\leopo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 12 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "100%|██████████| 10/10 [00:48<00:00,  4.81s/it]\n"
     ]
    }
   ],
   "source": [
    "import implicit\n",
    "model_als = implicit.als.AlternatingLeastSquares(factors=100, iterations=10, use_gpu=False)\n",
    "model_als.fit(user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "899862b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18420    45602451\n",
       "18293    60400014\n",
       "1211     16600231\n",
       "18407    26300705\n",
       "18398    26204628\n",
       "18514     7900440\n",
       "1235     13200828\n",
       "18517    38900074\n",
       "1016      1480544\n",
       "923      28720409\n",
       "Name: product_id, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_recommendations(model_als, user=2, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3aad725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map: 0.057643754834339936\n",
      "ndcg: 0.06650317209662725\n"
     ]
    }
   ],
   "source": [
    "maprec, ndcg = evaluate_model()\n",
    "print('map: {}\\nndcg: {}'.format(maprec, ndcg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
